{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image, ImageOps, ImageMath\n",
    "from astropy.utils.data import download_file\n",
    "from mpol.__init__ import zenodo_record\n",
    "from mpol import coordinates, gridding, fourier, losses, precomposed, utils\n",
    "from mpol.images import ImageCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "def RML_imager(visibility_file, cell_size, npix, learning_rate, n_iter, hyperparams_config, start_from_dirty_image=False, learning_rate_dim=None, n_iter_dim=None,):\n",
    "    '''---------------------------------------------------------------------------------------\n",
    "    Performs the RML imaging process using the SimpleNet model on the input visibilities\n",
    "    to produce surface brightness maps of the source in the image plane. Currently uses\n",
    "    only the NLL loss function, without other regularizers.\n",
    "\n",
    "    # TODO:\n",
    "    1. Start the training loop from the dirty image instead of a flat BaseCube. #*DONE*#\n",
    "    2. Implement regularizers in the loss function. #*DONE*#\n",
    "    3. Optimise regularisers to improve the quality of the final image.\n",
    "    4. Use cross-validation to find the best hyperparameters for the RML imaging process.\n",
    "    5. Compare the final image with that from CASA tclean.\n",
    "    6. Add functionality to save the final image cube as a FITS file.\n",
    "    7. Look into how to image multi-channel continuum visibilities into a single channel image.\n",
    "    ----------------------------------------------------------------------------------------'''\n",
    "\n",
    "    # create a directory to store the outputs of the RML imaging process\n",
    "    if not os.path.exists('RML_loop_outputs/'):\n",
    "        os.makedirs('RML_loop_outputs/')\n",
    "\n",
    "    # load the mock visibilities from the .npz file\n",
    "    d = np.load(visibility_file)\n",
    "    uu = d[\"uu\"]\n",
    "    vv = d[\"vv\"]\n",
    "    weight = d[\"weight\"]\n",
    "    data = d[\"data\"]\n",
    "    data_re = np.real(data)\n",
    "    data_im = np.imag(data)\n",
    "    nvis = len(uu)\n",
    "    print(f'Loaded visibilities from {visibility_file}.')\n",
    "    print(f'The dataset has {nvis} visibilities.\\n')\n",
    "\n",
    "    # check if the input cell size Nyquist samples the spatial frequency represented by the maximum u,v value\n",
    "    max_uv = np.max(np.array([uu,vv]))\n",
    "    max_cell_size = utils.get_maximum_cell_size(max_uv)\n",
    "    if cell_size > max_cell_size:\n",
    "        raise ValueError(f'The input cell size ({cell_size} arcseconds) does not Nyquist sample the spatial frequency represented by the maximum u,v value.\\nThe maximum cell_size that will still Nyquist sample the spatial frequency represented by the maximum u,v value is {max_cell_size:.2f} arcseconds).\\nPlease change the cell size to be less than {max_cell_size:.2f} arcseconds.\\n')\n",
    "    else:\n",
    "        print(f'The input cell size ({cell_size} arcseconds) Nyquist samples the spatial frequency represented by the maximum u,v value.\\n(The maximum cell_size that will still Nyquist sample the spatial frequency represented by the maximum u,v value is {max_cell_size:.2f} arcseconds).\\n')\n",
    "\n",
    "    # plot and save the downloaded (u,v) distribution\n",
    "    fig, ax = plt.subplots(nrows=1)\n",
    "    ax.scatter(uu, vv, s=1, rasterized=True, linewidths=0.0, c=\"k\")\n",
    "    ax.set_xlabel(r\"$u$ [k$\\lambda$]\")\n",
    "    ax.set_ylabel(r\"$v$ [k$\\lambda$]\")\n",
    "    ax.set_title(\"uv distribution\")\n",
    "    plt.savefig('RML_loop_outputs/uv_distribution.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'(u,v) distribution plot saved to: RML_loop_outputs/uv_distribution.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    # instantiate the gridcoords object\n",
    "    coords = coordinates.GridCoords(cell_size=cell_size, npix=npix)\n",
    "\n",
    "    # instantiate the dirty imager object\n",
    "    imager = gridding.DirtyImager(\n",
    "        coords=coords,\n",
    "        uu=uu,\n",
    "        vv=vv,\n",
    "        weight=weight,\n",
    "        data_re=data_re,\n",
    "        data_im=data_im,\n",
    "    )\n",
    "\n",
    "    # calculate the dirty image and the beam using Briggs weighting with robust=0.0\n",
    "    img, beam = imager.get_dirty_image(weighting=\"briggs\", robust=0.0)\n",
    "    print(f\"Calculated dirty beam and dirty image using Briggs weighting with robust=0.0.\")\n",
    "\n",
    "    # plot and save the calculated dirty image and dirty beam\n",
    "    chan = 0\n",
    "    kw = {\"origin\": \"lower\", \"interpolation\": \"none\", \"extent\": imager.coords.img_ext}\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(6, 3))\n",
    "    bmplot = ax[0].imshow(beam[chan], **kw)\n",
    "    #plt.colorbar(bmplot, ax=ax[0])\n",
    "    ax[0].set_title(\"Dirty beam\")\n",
    "    imgplot = ax[1].imshow(img[chan], **kw)\n",
    "    #plt.colorbar(imgplot, ax=ax[1])\n",
    "    ax[1].set_title(\"Dirty image\")\n",
    "    for a in ax:\n",
    "        a.set_xlabel(r\"$\\Delta \\alpha \\cos \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "        a.set_ylabel(r\"$\\Delta \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('RML_loop_outputs/dirty_beam_and_dirty_image.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'Dirty beam and dirty image plot saved to: RML_loop_outputs/dirty_beam_and_dirty_image.pdf')\n",
    "    plt.close()\n",
    "    print(f'The dirty image contains {np.sum(img < 0)} negative pixels.\\n')\n",
    "\n",
    "    # instantiate the data averager object\n",
    "    averager = gridding.DataAverager(\n",
    "        coords=coords,\n",
    "        uu=uu,\n",
    "        vv=vv,\n",
    "        weight=weight,\n",
    "        data_re=data_re,\n",
    "        data_im=data_im,\n",
    "        )\n",
    "\n",
    "    # convert the gridded visibilities to a pytorch dataset\n",
    "    dset = averager.to_pytorch_dataset()\n",
    "    print('Gridded and converted visibilities to a pytorch dataset.')\n",
    "    print(f\"The dataset has {dset.nchan} channel(s).\\n\") # TODO: Look into how to image multi-channel continuum visibilities into a single channel image.\n",
    "\n",
    "    if start_from_dirty_image:\n",
    "        # use the dirty image as the initial model image in BaseCube\n",
    "        # create a loss function corresponding to the mean squared error (MSE) between the RML model image pixel fluxes and the dirty image pixel fluxes and then optimize this RML model\n",
    "        # It calculates the loss based off of the image-plane distance between the dirty image and the state of the ImageCube in order to make the state of the ImageCube closer to the dirty image\n",
    "        ###-----------------------------------------------------------------------------------------------------------------###\n",
    "        print(f\"Starting the optimisation loop with {n_iter_dim} iterations to optimise the initial model image (BaseCube) based on the dirty image...\")\n",
    "        dirty_image = torch.tensor(img.copy())  # converts the dirty image into a pytorch tensor\n",
    "        rml_dim = precomposed.SimpleNet(coords=coords, nchan=dset.nchan) # initialise SimpleNet\n",
    "        optimizer_dim = torch.optim.SGD(rml_dim.parameters(), lr=learning_rate_dim) # instantiate the SGD optimizer\n",
    "\n",
    "        loss_tracker_dim = []\n",
    "        for i_dim in range(n_iter_dim):\n",
    "            optimizer_dim.zero_grad() # zero out any gradients attached to the tensor components so that they aren’t counted twice\n",
    "            rml_dim() # calculate the model visibilities from the current model image\n",
    "            sky_cube_dim = rml_dim.icube.sky_cube # get the model image from the BaseCube object\n",
    "            lossfunc_dim = torch.nn.MSELoss(reduction=\"sum\")  # the MSELoss calculates mean squared error (squared L2 norm)\n",
    "            loss_dim = (lossfunc_dim(sky_cube_dim, dirty_image)) ** 0.5 # square root of the MSE is our loss value\n",
    "            loss_tracker_dim.append(loss_dim.item()) # append the loss value to the loss tracker list\n",
    "            loss_dim.backward() # calculate the gradients of the loss with respect to the model parameters\n",
    "            optimizer_dim.step() # subtract the gradient image to the base image in order to advance base parameters in the direction of the minimum loss value\n",
    "\n",
    "        # plot the loss per iteration\n",
    "        fig, ax = plt.subplots(nrows=1)\n",
    "        ax.plot(loss_tracker_dim)\n",
    "        ax.set_xlabel(\"iteration\")\n",
    "        ax.set_ylabel(\"loss\")\n",
    "        ax.set_title(\"loss per iteration - L2 norm (MSE) between dirty image and BaseCube model image\")\n",
    "        plt.savefig('RML_loop_outputs/loss_per_iteration_dim.pdf', format='pdf', bbox_inches='tight')\n",
    "        print(f'Loss per iteration (for optimising the BaseCube image to the dirty image) plot saved to: RML_loop_outputs/loss_per_iteration_dim.pdf')\n",
    "        plt.close()\n",
    "\n",
    "        # plot the final model image (BaseCube) after the last iteration\n",
    "        img_dim = np.squeeze(rml_dim.icube.sky_cube.detach().numpy())\n",
    "        fig, ax = plt.subplots(nrows=1)\n",
    "        im_dim = ax.imshow(img_dim, origin=\"lower\", interpolation=\"none\", extent=rml_dim.icube.coords.img_ext)\n",
    "        plt.colorbar(im_dim)\n",
    "        plt.savefig('RML_loop_outputs/optimised_input_model_image_based_on_dirty_image.pdf', format='pdf', bbox_inches='tight')\n",
    "        print(f'Loss per iteration (for optimising the initial BaseCube to the dirty image) plot saved to: RML_loop_outputs/optimised_input_model_image_based_on_dirty_image.pdf')\n",
    "        plt.close()\n",
    "        print(f'The optimised initial image based on the dirty image contains {np.sum(img_dim < 0)} negative pixels.')\n",
    "\n",
    "        # save the optimised initial model image (BaseCube) to a .pt file\n",
    "        torch.save(rml_dim.state_dict(), \"RML_loop_outputs/dirty_image_model.pt\")\n",
    "        print('Optimised initial model image (BaseCube) based on the dirty image saved to: RML_loop_outputs/dirty_image_model.pt\\n')\n",
    "        ###-----------------------------------------------------------------------------------------------------------------###\n",
    "\n",
    "    # initialise SimpleNet\n",
    "    rml = precomposed.SimpleNet(coords=coords, nchan=dset.nchan)\n",
    "    print(f\"SimpleNet network initialised.\")\n",
    "\n",
    "    # choose the model image to set as the initial BaseCube\n",
    "    if start_from_dirty_image:\n",
    "        # load the optimised initial model image (BaseCube) from the .pt file\n",
    "        rml.load_state_dict(torch.load(\"RML_loop_outputs/dirty_image_model.pt\"))\n",
    "        print('Using optimised initial model image (loaded from: RML_loop_outputs/dirty_image_model.pt) based on the dirty image as the initial BaseCube image\\n')\n",
    "    else:\n",
    "        # use the default flat initial model image in the BaseCube\n",
    "        print('Starting from the default flat initial model image (BaseCube).\\n')\n",
    "\n",
    "    # Because we want to compute a clean set of gradient values in a later step, we “zero out” any gradients attached to the tensor components so that they aren’t counted twice.\n",
    "    rml.zero_grad()\n",
    "\n",
    "    # instantiate the SGD optimizer\n",
    "    optimizer = torch.optim.SGD(rml.parameters(), lr=learning_rate)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    start_time = time.time()\n",
    "    ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###\n",
    "    # initiate a list to store the loss values at each iteration\n",
    "    loss_tracker = []\n",
    "\n",
    "    # Run the training loop\n",
    "    print(f\"Starting the optimisation loop with {n_iter} iterations...\")\n",
    "    for i in range(n_iter):\n",
    "        rml.zero_grad()\n",
    "\n",
    "        # STEP 1: calculate the model visibilities from the current model image\n",
    "        vis = rml() # calculate model visibilities\n",
    "        sky_cube = rml.icube.sky_cube # get the current model 'sky' image\n",
    "\n",
    "        # STEP 2: calculate the loss between the model visibilities and the data visibilities\n",
    "        # loss = losses.nll_gridded(vis, dset) # loss function without regularizers, using only the NLL\n",
    "        loss = (\n",
    "            losses.nll_gridded(vis, dset)\n",
    "            + hyperparams_config[\"lambda_sparsity\"] * losses.sparsity(sky_cube)\n",
    "            + hyperparams_config[\"lambda_TV\"] * losses.TV_image(sky_cube)\n",
    "            + hyperparams_config[\"entropy\"] * losses.entropy(sky_cube, hyperparams_config[\"prior_intensity\"])\n",
    "            + hyperparams_config[\"TSV\"] * losses.TSV(sky_cube)\n",
    "        ) # loss function with regularizers #TODO: Implement regularizers properly and check how to get best hyperparameter values\n",
    "        loss_tracker.append(loss.item()) # append the loss value to the loss tracker list\n",
    "\n",
    "        # STEP 3: calculate the gradients of the loss with respect to the model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # STEP 4: subtract the gradient image to the base image in order to advance base parameters in the direction of the minimum loss value\n",
    "        optimizer.step()\n",
    "    ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###\n",
    "    end_time = time.time()\n",
    "    print('Done.')\n",
    "\n",
    "    # calculate the time taken for the optimisation loop to finish\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"The optimisation loop finished in {elapsed_time:.2f} seconds.\\n\")\n",
    "\n",
    "    # print the initial and final loss values\n",
    "    print(f\"Initial loss: {loss_tracker[0]:.2f}\")\n",
    "    print(f\"Final loss: {loss_tracker[-1]:.2f}\\n\")\n",
    "\n",
    "    # plot the loss per iteration\n",
    "    fig, ax = plt.subplots(nrows=1)\n",
    "    ax.plot(np.arange(n_iter), loss_tracker, marker=\".\", color=\"k\", linewidth=0.5)\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Loss per iteration\")\n",
    "    plt.savefig('RML_loop_outputs/loss_per_iteration.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'Loss per iteration plot saved to: RML_loop_outputs/loss_per_iteration.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    # detach the model 'sky' image from the computational graph and convert it to a numpy array\n",
    "    img_cube = rml.icube.sky_cube.detach().numpy() # TODO: Add functionality to save this image cube as a FITS file\n",
    "\n",
    "    # plot the final model image after the last iteration\n",
    "    fig, ax = plt.subplots(nrows=1)\n",
    "    im = ax.imshow(\n",
    "        np.squeeze(img_cube),\n",
    "        origin=\"lower\",\n",
    "        interpolation=\"none\",\n",
    "        extent=rml.icube.coords.img_ext,\n",
    "    )\n",
    "    ax.set_xlabel(r\"$\\Delta \\alpha \\cos \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "    ax.set_ylabel(r\"$\\Delta \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "    ax.set_title(\"Maximum likelihood image\")\n",
    "    plt.colorbar(im, label=r\"Jy/$\\mathrm{arcsec}^2$\")\n",
    "    plt.savefig('RML_loop_outputs/maximum_likelihood_image.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'Maximum likelihood image plot saved to: RML_loop_outputs/maximum_likelihood_image.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    return img_cube\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "###########################################################################################################################################\n",
    "visibility_file = '../data/visibilities/mock_visibilities_model_star_new.npz' # path to the .npz file containing the observed visibilities\n",
    "cell_size = 0.03 # arcseconds\n",
    "npix = 128 # number of pixels per image axis\n",
    "learning_rate = 3 # learning rate for the optimizer\n",
    "n_iter = 25 # number of iterations for the optimizer\n",
    "\n",
    "# hyperparameters used in the function and the optimizer (set those not being used to 0)\n",
    "hyperparams_config = (\n",
    "    {\"lambda_sparsity\": 7.0e-05,\n",
    "    \"lambda_TV\": 0.00,\n",
    "    \"entropy\": 1e-03,\n",
    "    \"prior_intensity\": 1.5e-07,\n",
    "    \"TSV\": 0.00,\n",
    "    \"epochs\": 1000,\n",
    "    }\n",
    ")\n",
    "\n",
    "start_from_dirty_image = False # If True, the initial BaseCube image is set to the dirty image, else to the default flat image.\n",
    "###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded visibilities from ../data/visibilities/mock_visibilities_model_star_new.npz.\n",
      "The dataset has 325080 visibilities.\n",
      "\n",
      "The input cell size (0.03 arcseconds) Nyquist samples the spatial frequency represented by the maximum u,v value.\n",
      "(The maximum cell_size that will still Nyquist sample the spatial frequency represented by the maximum u,v value is 0.09 arcseconds).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u,v) distribution plot saved to: RML_loop_outputs/uv_distribution.pdf\n",
      "\n",
      "Calculated dirty beam and dirty image using Briggs weighting with robust=0.0.\n",
      "Dirty beam and dirty image plot saved to: RML_loop_outputs/dirty_beam_and_dirty_image.pdf\n",
      "The dirty image contains 11266 negative pixels.\n",
      "\n",
      "Gridded and converted visibilities to a pytorch dataset.\n",
      "The dataset has 1 channel(s).\n",
      "\n",
      "Starting the optimisation loop with 1000 iterations to optimise the initial model image (BaseCube) based on the dirty image...\n",
      "Loss per iteration (for optimising the BaseCube image to the dirty image) plot saved to: RML_loop_outputs/loss_per_iteration_dim.pdf\n",
      "Loss per iteration (for optimising the initial BaseCube to the dirty image) plot saved to: RML_loop_outputs/optimised_input_model_image_based_on_dirty_image.pdf\n",
      "The optimised initial image based on the dirty image contains 0 negative pixels.\n",
      "Optimised initial model image (BaseCube) based on the dirty image saved to: RML_loop_outputs/dirty_image_model.pt\n",
      "\n",
      "SimpleNet network initialised.\n",
      "Using optimised initial model image (loaded from: RML_loop_outputs/dirty_image_model.pt) based on the dirty image as the initial BaseCube image\n",
      "\n",
      "Starting the optimisation loop with 25 iterations...\n",
      "Done.\n",
      "The optimisation loop finished in 0.14 seconds.\n",
      "\n",
      "Initial loss: 27.34\n",
      "Final loss: 27.32\n",
      "\n",
      "Loss per iteration plot saved to: RML_loop_outputs/loss_per_iteration.pdf\n",
      "\n",
      "Maximum likelihood image plot saved to: RML_loop_outputs/maximum_likelihood_image.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function call\n",
    "###########################################################################################################################################\n",
    "img_cube = RML_imager(visibility_file=visibility_file, cell_size=cell_size, npix=npix, learning_rate=learning_rate, n_iter=n_iter, hyperparams_config=hyperparams_config, start_from_dirty_image = True, learning_rate_dim=5, n_iter_dim=1000)\n",
    "###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
