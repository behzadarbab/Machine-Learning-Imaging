{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# redefining np.asscalar() and np.alen() to np.item() and np.len() to avoid deprecation errors\n",
    "###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###\n",
    "def patch_asscalar(a):\n",
    "    return a.item()\n",
    "setattr(np, \"asscalar\", patch_asscalar)\n",
    "\n",
    "def patch_alen(a):\n",
    "    return a.len()\n",
    "setattr(np, \"alen\", patch_alen)\n",
    "###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.utils.data import download_file\n",
    "\n",
    "from PIL import Image, ImageOps, ImageMath\n",
    "\n",
    "# Mpol utilities\n",
    "from mpol.__init__ import zenodo_record\n",
    "from mpol import coordinates, gridding, fourier, losses, precomposed, utils\n",
    "from mpol.images import ImageCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "def RML_imager(visibility_file, cell_size, npix, learning_rate, n_iter):\n",
    "    '''---------------------------------------------------------------------------------------\n",
    "    Performs the RML imaging process using the SimpleNet model on the input visibilities\n",
    "    to produce surface brightness maps of the source in the image plane. Currently uses\n",
    "    only the NLL loss function, without other regularizers.\n",
    "\n",
    "    # TODO:\n",
    "    1. Implement regularizers in the loss function.\n",
    "    2. Add functionality to save the final image cube as a FITS file.\n",
    "    3. Look into how to image multi-channel continuum visibilities into a single channel image.\n",
    "    ----------------------------------------------------------------------------------------'''\n",
    "\n",
    "    # create a directory to store the outputs of the RML imaging process\n",
    "    if not os.path.exists('RML_loop_outputs/'):\n",
    "        os.makedirs('RML_loop_outputs/')\n",
    "\n",
    "    # load the mock visibilities from the .npz file\n",
    "    d = np.load(visibility_file)\n",
    "    uu = d[\"uu\"]\n",
    "    vv = d[\"vv\"]\n",
    "    weight = d[\"weight\"]\n",
    "    data = d[\"data\"]\n",
    "    data_re = np.real(data)\n",
    "    data_im = np.imag(data)\n",
    "    nvis = len(uu)\n",
    "    print(f'Loaded visibilities from {visibility_file}.')\n",
    "    print(f'The dataset has {nvis} visibilities.\\n')\n",
    "\n",
    "    # check if the input cell size Nyquist samples the spatial frequency represented by the maximum u,v value\n",
    "    max_uv = np.max(np.array([uu,vv]))\n",
    "    max_cell_size = utils.get_maximum_cell_size(max_uv)\n",
    "    if cell_size > max_cell_size:\n",
    "        raise ValueError(f'The input cell size ({cell_size} arcseconds) does not Nyquist sample the spatial frequency represented by the maximum u,v value.\\nThe maximum cell_size that will still Nyquist sample the spatial frequency represented by the maximum u,v value is {max_cell_size:.2f} arcseconds).\\nPlease change the cell size to be less than {max_cell_size:.2f} arcseconds.\\n')\n",
    "    else:\n",
    "        print(f'The input cell size ({cell_size} arcseconds) Nyquist samples the spatial frequency represented by the maximum u,v value.\\n(The maximum cell_size that will still Nyquist sample the spatial frequency represented by the maximum u,v value is {max_cell_size:.2f} arcseconds).\\n')\n",
    "\n",
    "    # plot and save the downloaded (u,v) distribution\n",
    "    fig, ax = plt.subplots(nrows=1)\n",
    "    ax.scatter(uu, vv, s=1, rasterized=True, linewidths=0.0, c=\"k\")\n",
    "    ax.set_xlabel(r\"$u$ [k$\\lambda$]\")\n",
    "    ax.set_ylabel(r\"$v$ [k$\\lambda$]\")\n",
    "    ax.set_title(\"uv distribution\")\n",
    "    plt.savefig('RML_loop_outputs/uv_distribution.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'(u,v) distribution plot saved to: RML_loop_outputs/uv_distribution.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    # instantiate the gridcoords object\n",
    "    coords = coordinates.GridCoords(cell_size=cell_size, npix=npix)\n",
    "\n",
    "    # instantiate the dirty imager object\n",
    "    imager = gridding.DirtyImager(\n",
    "        coords=coords,\n",
    "        uu=uu,\n",
    "        vv=vv,\n",
    "        weight=weight,\n",
    "        data_re=data_re,\n",
    "        data_im=data_im,\n",
    "    )\n",
    "\n",
    "    # calculate the dirty image and the beam using Briggs weighting with robust=0.0\n",
    "    img, beam = imager.get_dirty_image(weighting=\"briggs\", robust=0.0)\n",
    "    print(f\"Calculated dirty beam and dirty image using Briggs weighting with robust=0.0.\")\n",
    "\n",
    "    # plot and save the calculated dirty image and dirty beam\n",
    "    chan = 0\n",
    "    kw = {\"origin\": \"lower\", \"interpolation\": \"none\", \"extent\": imager.coords.img_ext}\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(6, 3))\n",
    "    bmplot = ax[0].imshow(beam[chan], **kw)\n",
    "    #plt.colorbar(bmplot, ax=ax[0])\n",
    "    ax[0].set_title(\"Dirty beam\")\n",
    "    imgplot = ax[1].imshow(img[chan], **kw)\n",
    "    #plt.colorbar(imgplot, ax=ax[1])\n",
    "    ax[1].set_title(\"Dirty image\")\n",
    "    for a in ax:\n",
    "        a.set_xlabel(r\"$\\Delta \\alpha \\cos \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "        a.set_ylabel(r\"$\\Delta \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('RML_loop_outputs/dirty_beam_and_dirty_image.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'Dirty beam and dirty image plot saved to: RML_loop_outputs/dirty_beam_and_dirty_image.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    # instantiate the data averager object\n",
    "    averager = gridding.DataAverager(\n",
    "        coords=coords,\n",
    "        uu=uu,\n",
    "        vv=vv,\n",
    "        weight=weight,\n",
    "        data_re=data_re,\n",
    "        data_im=data_im,\n",
    "        )\n",
    "\n",
    "    # convert the gridded visibilities to a pytorch dataset\n",
    "    dset = averager.to_pytorch_dataset()\n",
    "    print('Gridded and converted visibilities to a pytorch dataset.')\n",
    "    print(f\"The dataset has {dset.nchan} channel(s).\\n\") # TODO: Look into how to image multi-channel continuum visibilities into a single channel image.\n",
    "\n",
    "    # initialise SimpleNet\n",
    "    rml = precomposed.SimpleNet(coords=coords, nchan=dset.nchan)\n",
    "    print(f\"SimpleNet newtwork initialised.\")\n",
    "\n",
    "    # Because we want to compute a clean set of gradient values in a later step, we “zero out” any gradients attached to the tensor components so that they aren’t counted twice.\n",
    "    rml.zero_grad()\n",
    "\n",
    "    # instantiate the SGD optimizer\n",
    "    optimizer = torch.optim.SGD(rml.parameters(), lr=learning_rate)\n",
    "\n",
    "    start_time = time.time()\n",
    "    ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###\n",
    "    # initiate a list to store the loss values at each iteration\n",
    "    loss_tracker = []\n",
    "\n",
    "    # loop over the number of iterations\n",
    "    print(f\"Starting the optimisation loop with {n_iter} iterations...\")\n",
    "    for i in range(n_iter):\n",
    "        rml.zero_grad()\n",
    "\n",
    "        # STEP 1: calculate the model visibilities from the current model image\n",
    "        vis = rml()\n",
    "\n",
    "        # STEP 2: calculate the loss between the model visibilities and the data visibilities\n",
    "        #NOTE: for now, the loss function is just the negative log likelihood (nll) only. Regularizers will be added later\n",
    "        loss = losses.nll_gridded(vis, dset) #TODO: Implement regularizers in the loss function\n",
    "        loss_tracker.append(loss.item()) # append the loss value to the loss tracker list\n",
    "\n",
    "        # STEP 3: calculate the gradients of the loss with respect to the model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # STEP 4: add the gradient image to the base image in order to advance base parameters in the direction of the minimum loss value\n",
    "        optimizer.step()\n",
    "    ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###\n",
    "    end_time = time.time()\n",
    "    print('Done.')\n",
    "\n",
    "    # calculate the time taken for the optimisation loop to finish\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"The optimisation loop finished in {elapsed_time:.2f} seconds.\\n\")\n",
    "\n",
    "    # plot the loss per iteration\n",
    "    fig, ax = plt.subplots(nrows=1)\n",
    "    ax.plot(np.arange(n_iter), loss_tracker, marker=\".\", color=\"k\", linewidth=0.5)\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Loss per iteration\")\n",
    "    plt.savefig('RML_loop_outputs/loss_per_iteration.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'Loss per iteration plot saved to: RML_loop_outputs/loss_per_iteration.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    # detach the model 'sky' image from the computational graph and convert it to a numpy array\n",
    "    img_cube = rml.icube.sky_cube.detach().numpy() # TODO: Add functionality to save this image cube as a FITS file\n",
    "\n",
    "    # plot the final model image after the last iteration\n",
    "    fig, ax = plt.subplots(nrows=1)\n",
    "    im = ax.imshow(\n",
    "        np.squeeze(img_cube),\n",
    "        origin=\"lower\",\n",
    "        interpolation=\"none\",\n",
    "        extent=rml.icube.coords.img_ext,\n",
    "    )\n",
    "    ax.set_xlabel(r\"$\\Delta \\alpha \\cos \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "    ax.set_ylabel(r\"$\\Delta \\delta$ [${}^{\\prime\\prime}$]\")\n",
    "    ax.set_title(\"Maximum likelihood image\")\n",
    "    plt.colorbar(im, label=r\"Jy/$\\mathrm{arcsec}^2$\")\n",
    "    plt.savefig('RML_loop_outputs/maximum_likelihood_image.pdf', format='pdf', bbox_inches='tight')\n",
    "    print(f'Maximum likelihood image plot saved to: RML_loop_outputs/maximum_likelihood_image.pdf\\n')\n",
    "    plt.close()\n",
    "\n",
    "    return img_cube\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "###########################################################################################################################################\n",
    "visibility_file = '../data/visibilities/mock_visibilities_model_star_new.npz' # path to the .npz file containing the observed visibilities\n",
    "cell_size = 0.03 # arcseconds\n",
    "npix = 128 # number of pixels per image axis\n",
    "learning_rate = 3.0e2 # learning rate for the optimizer\n",
    "n_iter = 250 # number of iterations for the optimizer\n",
    "###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded visibilities from ../data/visibilities/mock_visibilities_model_star_new.npz.\n",
      "The dataset has 325080 visibilities.\n",
      "\n",
      "The input cell size (0.03 arcseconds) Nyquist samples the spatial frequency represented by the maximum u,v value.\n",
      "(The maximum cell_size that will still Nyquist sample the spatial frequency represented by the maximum u,v value is 0.09 arcseconds).\n",
      "\n",
      "(u,v) distribution plot saved to: RML_loop_outputs/uv_distribution.pdf\n",
      "\n",
      "Calculated dirty beam and dirty image using Briggs weighting with robust=0.0.\n",
      "Dirty beam and dirty image plot saved to: RML_loop_outputs/dirty_beam_and_dirty_image.pdf\n",
      "\n",
      "Gridded and converted visibilities to a pytorch dataset.\n",
      "The dataset has 1 channel(s).\n",
      "\n",
      "SimpleNet newtwork initialised.\n",
      "Starting the optimisation loop with 250 iterations...\n",
      "Done.\n",
      "The optimisation loop finished in 0.89 seconds.\n",
      "\n",
      "Loss per iteration plot saved to: RML_loop_outputs/loss_per_iteration.pdf\n",
      "\n",
      "Maximum likelihood image plot saved to: RML_loop_outputs/maximum_likelihood_image.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function call\n",
    "###########################################################################################################################################\n",
    "img_cube = RML_imager(visibility_file=visibility_file, cell_size=cell_size, npix=npix, learning_rate=learning_rate, n_iter=n_iter)\n",
    "###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
